{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Resampling Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = sm.datasets.get_rdataset('Auto', 'ISLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ===============\n",
      "Auto R Documentation\n",
      "==== ===============\n",
      "\n",
      "Auto Data Set\n",
      "-------------\n",
      "\n",
      "Description\n",
      "~~~~~~~~~~~\n",
      "\n",
      "Gas mileage, horsepower, and other information for 392 vehicles.\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "::\n",
      "\n",
      "   Auto\n",
      "\n",
      "Format\n",
      "~~~~~~\n",
      "\n",
      "A data frame with 392 observations on the following 9 variables.\n",
      "\n",
      "``mpg``\n",
      "   miles per gallon\n",
      "\n",
      "``cylinders``\n",
      "   Number of cylinders between 4 and 8\n",
      "\n",
      "``displacement``\n",
      "   Engine displacement (cu. inches)\n",
      "\n",
      "``horsepower``\n",
      "   Engine horsepower\n",
      "\n",
      "``weight``\n",
      "   Vehicle weight (lbs.)\n",
      "\n",
      "``acceleration``\n",
      "   Time to accelerate from 0 to 60 mph (sec.)\n",
      "\n",
      "``year``\n",
      "   Model year (modulo 100)\n",
      "\n",
      "``origin``\n",
      "   Origin of car (1. American, 2. European, 3. Japanese)\n",
      "\n",
      "``name``\n",
      "   Vehicle name\n",
      "\n",
      "The orginal data contained 408 observations but 16 observations with\n",
      "missing values were removed.\n",
      "\n",
      "Source\n",
      "~~~~~~\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at\n",
      "Carnegie Mellon University. The dataset was used in the 1983 American\n",
      "Statistical Association Exposition.\n",
      "\n",
      "References\n",
      "~~~~~~~~~~\n",
      "\n",
      "James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) *An\n",
      "Introduction to Statistical Learning with applications in R*,\n",
      "`www.StatLearning.com <www.StatLearning.com>`__, Springer-Verlag, New\n",
      "York\n",
      "\n",
      "Examples\n",
      "~~~~~~~~\n",
      "\n",
      "::\n",
      "\n",
      "   pairs(Auto)\n",
      "   attach(Auto)\n",
      "   hist(mpg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(auto.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "dauto = auto.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Split - MSE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "X = dauto['horsepower']\n",
    "y = dauto['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression horsepower onto mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.591\n",
      "Model:                            OLS   Adj. R-squared:                  0.589\n",
      "Method:                 Least Squares   F-statistic:                     280.5\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           1.54e-39\n",
      "Time:                        10:04:04   Log-Likelihood:                -586.12\n",
      "No. Observations:                 196   AIC:                             1176.\n",
      "Df Residuals:                     194   BIC:                             1183.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         39.5927      1.014     39.037      0.000      37.592      41.593\n",
      "horsepower    -0.1565      0.009    -16.749      0.000      -0.175      -0.138\n",
      "==============================================================================\n",
      "Omnibus:                       10.071   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.764\n",
      "Skew:                           0.453   Prob(JB):                      0.00460\n",
      "Kurtosis:                       3.704   Cond. No.                         319.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lr = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.80212062059356\n"
     ]
    }
   ],
   "source": [
    "# lr = LinearRegression()\n",
    "# lr.fit(x_train.to_frame(),y_train)\n",
    "# pred = lr.predict(x_test.to_frame())\n",
    "# print('Mean squared error is ',mean_squared_error(y_test,pred))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = lr.predict(sm.add_constant(X_test))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test,y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression horsepower onto mpg (using polynomial 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.657\n",
      "Model:                            OLS   Adj. R-squared:                  0.653\n",
      "Method:                 Least Squares   F-statistic:                     184.7\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           1.49e-45\n",
      "Time:                        10:04:06   Log-Likelihood:                -568.96\n",
      "No. Observations:                 196   AIC:                             1144.\n",
      "Df Residuals:                     193   BIC:                             1154.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         23.6214      0.317     74.408      0.000      22.995      24.248\n",
      "x1           -81.0421      4.444    -18.235      0.000     -89.808     -72.276\n",
      "x2            27.0090      4.444      6.077      0.000      18.243      35.775\n",
      "==============================================================================\n",
      "Omnibus:                       11.072   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               21.097\n",
      "Skew:                           0.223   Prob(JB):                     2.62e-05\n",
      "Kurtosis:                       4.544   Cond. No.                         14.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def ortho_poly_fit(x, degree = 1):\n",
    "    n = degree + 1\n",
    "    x = np.asarray(x).flatten()\n",
    "    if(degree >= len(np.unique(x))):\n",
    "            stop(\"'degree' must be less than number of unique points\")\n",
    "    xbar = np.mean(x)\n",
    "    x = x - xbar\n",
    "    X = np.fliplr(np.vander(x, n))\n",
    "    q,r = np.linalg.qr(X)\n",
    "\n",
    "    z = np.diag(np.diag(r))\n",
    "    raw = np.dot(q, z)\n",
    "\n",
    "    norm2 = np.sum(raw**2, axis=0)\n",
    "    alpha = (np.sum((raw**2)*np.reshape(x,(-1,1)), axis=0)/norm2 + xbar)[:degree]\n",
    "    Z = raw / np.sqrt(norm2)\n",
    "    return Z, norm2, alpha\n",
    "\n",
    "\n",
    "X_train2 = sm.add_constant(ortho_poly_fit(X_train.values,2)[0][:,1:])\n",
    "y_train2 = y_train\n",
    "\n",
    "lr2 = sm.OLS(y_train2, X_train2).fit()\n",
    "print(lr2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.94779122522533\n"
     ]
    }
   ],
   "source": [
    "y_preds2 = lr2.predict(sm.add_constant(ortho_poly_fit(X_test.values,2)[0][:,1:]))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test,y_preds2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression horsepower onto mpg (using polynomial 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.657\n",
      "Model:                            OLS   Adj. R-squared:                  0.652\n",
      "Method:                 Least Squares   F-statistic:                     122.6\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           2.23e-44\n",
      "Time:                        10:04:07   Log-Likelihood:                -568.93\n",
      "No. Observations:                 196   AIC:                             1146.\n",
      "Df Residuals:                     192   BIC:                             1159.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         23.6214      0.318     74.227      0.000      22.994      24.249\n",
      "x1           -81.0421      4.455    -18.190      0.000     -89.830     -72.254\n",
      "x2            27.0090      4.455      6.062      0.000      18.221      35.797\n",
      "x3            -1.0919      4.455     -0.245      0.807      -9.879       7.696\n",
      "==============================================================================\n",
      "Omnibus:                       11.037   Durbin-Watson:                   1.921\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               21.174\n",
      "Skew:                           0.218   Prob(JB):                     2.52e-05\n",
      "Kurtosis:                       4.550   Cond. No.                         14.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_train3 = sm.add_constant(ortho_poly_fit(X_train.values,3)[0][:,1:])\n",
    "y_train3 = y_train\n",
    "\n",
    "lr3 = sm.OLS(y_train3, X_train3).fit()\n",
    "print(lr3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.90233627602706\n"
     ]
    }
   ],
   "source": [
    "y_preds3 = lr3.predict(sm.add_constant(ortho_poly_fit(X_test.values,3)[0][:,1:]))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test,y_preds3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Split - MSE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "X1 = dauto['horsepower']\n",
    "y1 = dauto['mpg']\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1,\n",
    "                                                   y1,\n",
    "                                                   test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression horsepower onto mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.614\n",
      "Model:                            OLS   Adj. R-squared:                  0.612\n",
      "Method:                 Least Squares   F-statistic:                     308.5\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           5.83e-42\n",
      "Time:                        10:04:08   Log-Likelihood:                -592.23\n",
      "No. Observations:                 196   AIC:                             1188.\n",
      "Df Residuals:                     194   BIC:                             1195.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         40.8582      1.036     39.431      0.000      38.815      42.902\n",
      "horsepower    -0.1648      0.009    -17.565      0.000      -0.183      -0.146\n",
      "==============================================================================\n",
      "Omnibus:                       10.932   Durbin-Watson:                   2.173\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.512\n",
      "Skew:                           0.593   Prob(JB):                      0.00316\n",
      "Kurtosis:                       3.069   Cond. No.                         321.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lr11 = sm.OLS(y1_train, sm.add_constant(X1_train)).fit()\n",
    "print(lr11.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23.442643969985753\n"
     ]
    }
   ],
   "source": [
    "y1_preds = lr11.predict(sm.add_constant(X1_test))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y1_test,y1_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression horsepower onto mpg (using polynomial 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.695\n",
      "Model:                            OLS   Adj. R-squared:                  0.691\n",
      "Method:                 Least Squares   F-statistic:                     219.4\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           1.99e-50\n",
      "Time:                        10:04:08   Log-Likelihood:                -569.29\n",
      "No. Observations:                 196   AIC:                             1145.\n",
      "Df Residuals:                     193   BIC:                             1154.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         23.7689      0.318     74.747      0.000      23.142      24.396\n",
      "x1           -87.6815      4.452    -19.695      0.000     -96.462     -78.901\n",
      "x2            31.7648      4.452      7.135      0.000      22.984      40.545\n",
      "==============================================================================\n",
      "Omnibus:                        9.844   Durbin-Watson:                   2.067\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               14.226\n",
      "Skew:                           0.306   Prob(JB):                     0.000814\n",
      "Kurtosis:                       4.169   Cond. No.                         14.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X1_train2 = sm.add_constant(ortho_poly_fit(X1_train.values,2)[0][:,1:])\n",
    "y1_train2 = y1_train\n",
    "\n",
    "lr12 = sm.OLS(y1_train2, X1_train2).fit()\n",
    "print(lr12.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.93937268206552\n"
     ]
    }
   ],
   "source": [
    "y1_preds2 = lr12.predict(sm.add_constant(ortho_poly_fit(X1_test.values,2)[0][:,1:]))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y1_test,y1_preds2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression horsepower onto mpg (using polynomial 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.695\n",
      "Model:                            OLS   Adj. R-squared:                  0.690\n",
      "Method:                 Least Squares   F-statistic:                     145.5\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           3.30e-49\n",
      "Time:                        10:04:09   Log-Likelihood:                -569.28\n",
      "No. Observations:                 196   AIC:                             1147.\n",
      "Df Residuals:                     192   BIC:                             1160.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         23.7689      0.319     74.557      0.000      23.140      24.398\n",
      "x1           -87.6815      4.463    -19.645      0.000     -96.485     -78.878\n",
      "x2            31.7648      4.463      7.117      0.000      22.962      40.568\n",
      "x3             0.6514      4.463      0.146      0.884      -8.152       9.455\n",
      "==============================================================================\n",
      "Omnibus:                        9.793   Durbin-Watson:                   2.062\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               13.839\n",
      "Skew:                           0.314   Prob(JB):                     0.000988\n",
      "Kurtosis:                       4.141   Cond. No.                         14.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X1_train3 = sm.add_constant(ortho_poly_fit(X1_train.values,3)[0][:,1:])\n",
    "y1_train3 = y1_train\n",
    "\n",
    "lr13 = sm.OLS(y1_train3, X1_train3).fit()\n",
    "print(lr13.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18.981572123945305\n"
     ]
    }
   ],
   "source": [
    "y1_preds3 = lr13.predict(sm.add_constant(ortho_poly_fit(X1_test.values,3)[0][:,1:]))\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y1_test,y1_preds3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "X = dauto['horsepower']\n",
    "y = dauto['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.23151351792923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "\n",
    "\n",
    "crossvalidation = KFold(n_splits=392, random_state=None, shuffle=False)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train.to_frame(),y_train)\n",
    "pred = lr.predict(X_test.to_frame())\n",
    "\n",
    "\n",
    "scores = cross_val_score(lr, X.to_frame(), y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "\n",
    "print(\"MSE: \" + str(np.mean(np.abs(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " polynomial 1 MSE: 24.231513517929226, STD: 36.797315036405344\n",
      " polynomial 2 MSE: 19.248213124489787, STD: 34.99844615178275\n",
      " polynomial 3 MSE: 19.334984064101494, STD: 35.76513567801889\n",
      " polynomial 4 MSE: 19.424430308672896, STD: 35.68335275574849\n",
      " polynomial 5 MSE: 19.033217373107604, STD: 35.31732327822555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for i in range(1,6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(X.to_frame())\n",
    "    model = lr.fit(X_current, y)\n",
    "    scores = cross_val_score(model, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "    \n",
    "    print(\" polynomial \" +str(i)+ \" MSE: \" + str(np.mean(np.abs(scores)))+ \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " polynomial 1 MSE: 27.439933652339864, STD: 14.51025071128113\n",
      " polynomial 2 MSE: 21.23584005580157, STD: 11.797327528897423\n",
      " polynomial 3 MSE: 21.336606183492073, STD: 11.844339714946903\n",
      " polynomial 4 MSE: 21.3538869961286, STD: 11.98633234961832\n",
      " polynomial 5 MSE: 20.905603446050055, STD: 12.185477989682207\n",
      " polynomial 6 MSE: 20.78789280660235, STD: 12.145705434704288\n",
      " polynomial 7 MSE: 20.953757892685807, STD: 12.059643641417342\n",
      " polynomial 8 MSE: 21.077118806792964, STD: 12.04446801214061\n",
      " polynomial 9 MSE: 21.036937754093266, STD: 11.948358265914973\n",
      " polynomial 10 MSE: 20.985037880274767, STD: 11.80440968886917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "X = dauto['horsepower'].to_frame()\n",
    "y = dauto['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.5)\n",
    "lr = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "for i in range(1,11):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(X)\n",
    "    model = lr.fit(X_current, y)\n",
    "    scores = cross_val_score(model, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "    \n",
    "    print(\" polynomial \" +str(i)+ \" MSE: \" + str(np.mean(np.abs(scores)))+ \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= ===============\n",
      "Portfolio R Documentation\n",
      "========= ===============\n",
      "\n",
      "Portfolio Data\n",
      "--------------\n",
      "\n",
      "Description\n",
      "~~~~~~~~~~~\n",
      "\n",
      "A simple simulated data set containing 100 returns for each of two\n",
      "assets, X and Y. The data is used to estimate the optimal fraction to\n",
      "invest in each asset to minimize investment risk of the combined\n",
      "portfolio. One can then use the Bootstrap to estimate the standard error\n",
      "of this estimate.\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "::\n",
      "\n",
      "   Portfolio\n",
      "\n",
      "Format\n",
      "~~~~~~\n",
      "\n",
      "A data frame with 100 observations on the following 2 variables.\n",
      "\n",
      "``X``\n",
      "   Returns for Asset X\n",
      "\n",
      "``Y``\n",
      "   Returns for Asset Y\n",
      "\n",
      "Source\n",
      "~~~~~~\n",
      "\n",
      "Simulated data\n",
      "\n",
      "References\n",
      "~~~~~~~~~~\n",
      "\n",
      "James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) *An\n",
      "Introduction to Statistical Learning with applications in R*,\n",
      "`www.StatLearning.com <www.StatLearning.com>`__, Springer-Verlag, New\n",
      "York\n",
      "\n",
      "Examples\n",
      "~~~~~~~~\n",
      "\n",
      "::\n",
      "\n",
      "   summary(Portfolio)\n",
      "   attach(Portfolio)\n",
      "   plot(X,Y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "portfolio = sm.datasets.get_rdataset('Portfolio', 'ISLR')\n",
    "print(portfolio.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "dportfolio = portfolio.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(data, index):\n",
    "    X = data['X'].loc[index]\n",
    "    Y = data['Y'].loc[index]\n",
    "    return ((np.var(Y)-np.cov(X,Y)[0][1])/(np.var(X)+np.var(Y)-2*np.cov(X,Y)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5766511516104116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha(dportfolio,np.arange(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491078066222176"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "i = resample(np.arange(0,100), n_samples=100, random_state=2, replace=True)\n",
    "alpha(dportfolio,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot(data,func,R):\n",
    "    estimates = []\n",
    "    for i in range(R):\n",
    "        estimates.append(func(data,resample(np.arange(0,len(data)), n_samples=len(data), replace=True)))\n",
    "    df = pd.DataFrame(estimates)\n",
    "    bootstrap_statistics = {'estimated_value':np.mean(np.array(df.values),axis=0),'std_error':np.std(np.array(df.values),axis=0)}   \n",
    "    return bootstrap_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimated_value': array([0.58009862]), 'std_error': array([0.0915255])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = boot(dportfolio,alpha,1000)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(data,index):\n",
    "    X = data['horsepower'].loc[index]\n",
    "    y = data['mpg'].loc[index]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X.to_frame(),y)\n",
    "    intercept = lr.intercept_\n",
    "    coef = lr.coef_\n",
    "    return [intercept,coef[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.40042993121894, -0.15927786906064584]\n"
     ]
    }
   ],
   "source": [
    "dauto1 = dauto.reset_index()\n",
    "print(boot_fn(dauto1,resample(np.arange(0,392), n_samples=100, replace=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.693439525976096, -0.15423909195849003]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(boot_fn(dauto1,resample(np.arange(0,392), n_samples=100, replace=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.15000955774242, -0.15116600864364851]\n"
     ]
    }
   ],
   "source": [
    "print(boot_fn(dauto1,resample(np.arange(0,392), n_samples=100, replace=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimated_value': array([39.96338479, -0.1583057 ]),\n",
       " 'std_error': array([0.82526625, 0.00713573])}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "boot(dauto1,boot_fn,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.591\n",
      "Model:                            OLS   Adj. R-squared:                  0.589\n",
      "Method:                 Least Squares   F-statistic:                     280.5\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           1.54e-39\n",
      "Time:                        10:42:11   Log-Likelihood:                -586.12\n",
      "No. Observations:                 196   AIC:                             1176.\n",
      "Df Residuals:                     194   BIC:                             1183.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         39.5927      1.014     39.037      0.000      37.592      41.593\n",
      "horsepower    -0.1565      0.009    -16.749      0.000      -0.175      -0.138\n",
      "==============================================================================\n",
      "Omnibus:                       10.071   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.764\n",
      "Skew:                           0.453   Prob(JB):                      0.00460\n",
      "Kurtosis:                       3.704   Cond. No.                         319.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X = dauto1['horsepower'].to_frame()\n",
    "y = dauto1['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.5)\n",
    "lr = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### polynomial horse with bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(data,index):\n",
    "    \n",
    "    x = data['horsepower'].to_frame()\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_current = poly.fit_transform(x)[index]\n",
    "    y = data['mpg'].loc[index]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_current, y)\n",
    "    intercept = lr.intercept_\n",
    "    coef =lr.coef_\n",
    "    \n",
    "    return [intercept,coef[1], coef[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimated_value': array([ 5.68082795e+01, -4.64974801e-01,  1.22711212e-03]),\n",
       " 'std_error': array([2.09757065e+00, 3.35744253e-02, 1.21825719e-04])}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "boot(dauto1,boot_fn,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.688\n",
      "Model:                            OLS   Adj. R-squared:                  0.686\n",
      "Method:                 Least Squares   F-statistic:                     428.0\n",
      "Date:                Mon, 08 Feb 2021   Prob (F-statistic):           5.40e-99\n",
      "Time:                        10:45:44   Log-Likelihood:                -1133.2\n",
      "No. Observations:                 392   AIC:                             2272.\n",
      "Df Residuals:                     389   BIC:                             2284.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         56.9001      1.800     31.604      0.000      53.360      60.440\n",
      "x1            -0.4662      0.031    -14.978      0.000      -0.527      -0.405\n",
      "x2             0.0012      0.000     10.080      0.000       0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                       16.158   Durbin-Watson:                   1.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.662\n",
      "Skew:                           0.218   Prob(JB):                     2.20e-07\n",
      "Kurtosis:                       4.299   Cond. No.                     1.29e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.29e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = pd.DataFrame(dauto1['horsepower'])\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_current = poly.fit_transform(x)\n",
    "y = dauto1['mpg']\n",
    "lr = sm.OLS(y,X_current).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
